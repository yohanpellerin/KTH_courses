{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AALnQO-y6HOz"
   },
   "source": [
    "# ***Reparameterization of common distributions***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRc3KUnVPHm9"
   },
   "source": [
    "We will work with Torch throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hD0wA4YPFzy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Beta #, ...  import the distributions you need here\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSQ2cI-_QeEW"
   },
   "source": [
    "A helper function to visualize the generated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8U4TWTzs9KVd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def compare_samples (samples_1, samples_2, bins=100, range=None):\n",
    "  fig = plt.figure()\n",
    "  if range is not None:\n",
    "    plt.hist(samples_1, bins=bins, range=range)\n",
    "    plt.hist(samples_2, bins=bins, range=range)\n",
    "  else:\n",
    "    plt.hist(samples_1, bins=bins)\n",
    "    plt.hist(samples_2, bins=bins)\n",
    "  plt.xlabel('value')\n",
    "  plt.ylabel('number of samples')\n",
    "  plt.legend(['direct','via reparameterization'])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UcchbfK_isG"
   },
   "source": [
    "### ***Q1. Exponential Distribution***\n",
    "Below write a function that generates N samples from $Exp (\\lambda)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3Phd_jt_xcl"
   },
   "outputs": [],
   "source": [
    "def exp_sampler(l, N):\n",
    "  # insert your code\n",
    "  return samples # should be N-by-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wX19swaIRzGa"
   },
   "source": [
    "Now, implement the reparameterization trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTc92D_k_zvT"
   },
   "outputs": [],
   "source": [
    "def exp_reparametrize(l,N):\n",
    "  # this function should return N samples via reparametrization,\n",
    "  # insert your code\n",
    "  return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP_klfnoSMOf"
   },
   "source": [
    "Generate samples for $\\lambda = 1$ and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQeU4IXoAWFd"
   },
   "outputs": [],
   "source": [
    "l = 1    #lambda\n",
    "N = 1000\n",
    "direct_samples = exp_sampler(l, N)\n",
    "reparametrized_samples = exp_reparametrize(l, N)\n",
    "compare_samples(direct_samples, reparametrized_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oSfkJfGAzNH"
   },
   "source": [
    "### ***Q2. Categorical Distribution***\n",
    "Below write a function that generates N samples from Categorical (**a**), where **a** = $[a_0, a_1, a_2, a_3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsBBxMRgBLIu"
   },
   "outputs": [],
   "source": [
    "def categorical_sampler(a, N):\n",
    "  # insert your code\n",
    "\n",
    "  return samples  # should be N-by-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZalUgMQTC68"
   },
   "source": [
    "Now write a function that generates samples from Categorical (**a**) via reparameterization:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxe9O-RIBSRN"
   },
   "outputs": [],
   "source": [
    "# Hint: approximate the Categorical distribution with the Gumbel-Softmax distribution\n",
    "def categorical_reparametrize(a, N, temp=0.1, eps=1e-20):  # temp and eps are hyperparameters for Gumbel-Softmax\n",
    "  # insert your code\n",
    "\n",
    "\n",
    "  return samples # make sure that your implementation allows the gradient to backpropagate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afyIAchkVVnh"
   },
   "source": [
    "Generate samples when $a = [0.1,0.2,0.5,0.2]$ and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxvilsshB7yS"
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([0.1,0.2,0.5,0.2])\n",
    "N = 1000\n",
    "direct_samples = categorical_sampler(a, N)\n",
    "reparametrized_samples = categorical_reparametrize(a, N, temp=0.1, eps=1e-20)\n",
    "compare_samples(direct_samples, reparametrized_samples)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
